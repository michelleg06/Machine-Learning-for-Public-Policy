---
#title: "Supervised Machine Learning: Linear Models (Regression)"
#author: "Dr. Stephan Dietrich & Michelle Gonz√°lez Amador"
#date: '2022-09-21'
output: html_document
---


## **Supervised Machine Learning: Linear Models (Regression)** {.tabset .tabset-fade .tabset-pills}

### **Merging datasets with R: LSMS data example**

Many organisations, institutions, and firms around the world collect and, if we're lucky, share data. One such example is The World Bank Group who, in cooperation with local statistical offices, collects cross-sectional and panel data on the socioeconomic lives of country nationals. The Living Standards Measurement Survey (LSMS, for short) has been around since the 1980's, and anyone who wishes to analyse that data for (hopefully!) policy-improvement purposes can do so. The only problem is, it comes in various formats and separate files. We've chosen to download the 2019-2020 LSMS data for Malawi, a cross-sectional database which contains several modules on Health, Education, Food Security, etc. When you download the data, you receive a folder with several .csv files that must be put together. The code below does just that.

**1. Preliminaries: setting working directory and opening libraries**

```{r}
# 1.1 Cleaning the working environment and setting up the working directory path
rm(list = ls())
setwd("~/Desktop/Malawi2019")
# 1.2 Opening libraries

#install.packages("tidyverse","data.table")
library(tidyverse)
library(data.table)

```

**2. Uploading the data**

We will be working with the Malawi dataset from the LSMS surveys from the World Bank Group. To download and merge the data, you can refer to the documentation: [World Bank Microdata: LSMS Malawi](https://microdata.worldbank.org/index.php/catalog/3818/related-materials).

```{r}
# The following like will look inside the folder defined by file.path() command and collect the names of all the files that contain the word patterns "hh_mod". 
filedir <- file.path("~/Desktop/Malawi2019")
filenames <- list.files(filedir,pattern="hh_mod", full.names=TRUE, recursive=FALSE, ignore.case=TRUE)

# data object now contains all files from the 2019 round from the Household Module
print(filenames)

# We will now create function that will read all the files referenced in the filenames object and assign an an object to them (each file will become an element within a list).

datList <- lapply(filenames, function(i) {
    df <- read.csv(i, header=TRUE, strip.white=TRUE)
    return(df)
}) # this function should read all the *listed* files from above, convert them into a data frame and store them in a list

head(datList[[1]]) # returns the first elements in the first dataframe from the list datList

# A smart thing to do is to clean your Global Environment every so often when you are done with an object, to free up some memory
rm(filenames, filedir)

```
Note that the order of the datasets within datList follows the order of the names in filenames, such that dataset hh_mod_a_filt.csv would be 1,  HH_MOD_B.csv would be 2, and so forth.

**3. Merging data **

Now that we have succesfully uploaded all the files from our folder, we want to merge the datasets stored in the list (datList):

- We want to merge the first dataset [module A], containing household level information, with module B, a Household Roster with Individual level information. The variable *case_id* is the unique identifier at the household level, and it is present in both datasets.

```{r}

datAB <- merge(datList[[1]], datList[[2]], by="case_id", all = TRUE)

```

Let's do some sanity checks to see whether our merging worked as intended:

```{r}

# number of rows and columns of module A
dim(datList[[1]]) # 11434 rows, 21 columns
# number of rows and columns of module B
dim(datList[[2]]) # 50476 rows, 53 columns
# number of rows and columns of our merged data. Rows MUST be the same as module B
dim(datAB) # 50476 rows # 73 columns
# notice that the number of columns = Cols A + Cols B -1[variable we used to merge]

#Brief overview of our new dataset/dataframe!
str(datAB)
```

Something that you might find interesting is that the numeric variable *case_id* (which we used to merge) looks odd. This is due to the fact that R is reading this number in scientific form, if you'd like to see the standard number:

```{r}
options(scipen = 100) # run this line to turn off scientific form, to set it back use options(scipen = 0)

```

Now you can run the *str(datAB)* line again and see the *case_id* variable in standard form.
Let's further merge dataframe datAB with module C, which contains individual level data on Education. The individual unique identifier, which exists in Module B, and C (and now also in datAB after the merge) is *PID*:

```{r}
datABC <- merge(datAB, datList[[3]], by=c("case_id","PID"), all = TRUE)

```

We use the household unique identifier, *case_id*, to match households and the individual unique identifier, *PID*, to match individuals within each household. The dataframe should increase in column number, but not in number of observations (feel free to check using dim() or in the global environment).# We should select other relevant modules from the IHS5 Household Database: D[Health; case_id PID], E[Time Use & Labour; case_id PID], F[Housing, case_id], H[Food Security, case_id], T[Subjective Assessment of Well-Being, case_id]:

```{r}

datABCD <- merge(datABC, datList[[4]], by=c("case_id","PID"), all = TRUE)
datABCDE <- merge(datABCD, datList[[5]], by=c("case_id","PID"), all = TRUE)

```

There's a warning! It isn't a big deal (the code still did it's job), but let's try to sort it out anyways.Dataframe datABCD contains already variables HHID.x and HHID.y. Dataframe datABCDE now contains HHID, HHID.x and HHID.y, so perhaps it would be prudent to delete two of the three duplicates:

```{r}

# let's find out the position of these two columns in the dataframe
which( colnames(datABCDE)=="HHID.x") # 3 and 74
which( colnames(datABCDE)=="HHID.y") # 23 and 129
which( colnames(datABCDE)=="HHID") # 187 (let's keep this guy)
datABCDE <- datABCDE[,-c(3,23,74,129)] # this line removes the four selected duplicated columns.

```
Note that as we continue to merge multiple modules these duplicated columns will reappear. This happens when two datasets containg the same vector besides the unique identifier. 

```{r}
#Merging Module F (Housing)
datABCDEF <- merge(datABCDE, datList[[6]], by="case_id", all = TRUE)
```

Up until this point, the order of datList dataframes and Modules was the same (1-A,2-B,3-C, etc.). Now, we need to take into account that there exist modules F1, G1, G2 etc.You can refer to Table 10: Structure of the IHS5 Household Database of the [Basic Information Document](https://microdata.worldbank.org/index.php/catalog/2939/related-materials) to confirm the correct order.


```{r}
datABCDEFH <- merge(datABCDEF, datList[[11]], by="case_id", all = TRUE)
datABCDEFHT <- merge(datABCDEFH, datList[[28]], by="case_id", all = TRUE)
which( colnames(datABCDEFHT)=="HHID.x") # 183 454
which( colnames(datABCDEFHT)=="HHID.y") # 340 494
datABCDEFHT <- datABCDEFHT[,-c(454,340,494)]
names(datABCDEFHT)[names(datABCDEFHT) == "HHID.x"] <- "HHID" # change the name of the non-eliminated HHID.x column to HHID

```

We should also include some information on consumption:

```{r}
# G1[Food Consumption Over Past One Week; case_id hh_g02] 8
# This module collects information on all food consumed by the household in the past 7 days
datG1 = datList[[8]]

datG1 <- datG1[,c(1,7,8)] # I only want to keep the unique household identifier, item code,  and the total amount consumed in the past week.
# We want to create a vector (variable) that contains one single number: the total amount spent on food in the past 7 days.

# Initialise empty vectors for 'for' loop
list <- unique(datG1$case_id) # list is an object containing only
idx  <- NA
hold <- NA
sumConsumption <- NA
temp <- NA
data <- NA

for (i in 1:length(list)) { # iterate over the number of elements in object 'list' 
        
        idx    <- which(datG1$case_id == list[i]) #index containing the unique id that matches the iteration number
        hold   <- datG1[idx,] # vector containing all the elements that match the previous indicator
        sumConsumption  <- sum(hold$hh_g03a, na.rm = TRUE) # sum all the values contained in food item consumption (hh_g03a) vector (in $)
        
        temp <- cbind(hold$case_id,sumConsumption) # create a temporary object with the two concatenated vectors: the unique identifier and the final consumption variable
        data  <- rbind(data,temp) # append the temporary object to dataframe data
        
}

# Make sure that the object data is stored correctly: dataframe type
datG <- as.data.frame(data)

# let's keep only one observation per household
datG <- unique(datG)
# Now let's rename the variable and merge our consumption data!
names(datG)[names(datG) == "V1"] <- "case_id"
# The first row is empty, let's get rid of it
datG <- datG[-1,]

datABCDEFHTG1 <- merge(datABCDEFHT, datG, by="case_id", all = TRUE)

# save/export the final, merged dataset
write_rds(datABCDEFHTG1, "Malawi_2019(2).rds","xz", compression = 9L)

```

You can download the final product by clicking on the button below.
```{r, echo=FALSE}
library(downloadthis)
download_link(
  link = "https://github.com/michelleg06/Machine-Learning-for-Public-Policy/blob/main/Malawi_2019.rds",
  button_label = "Download merged file (.rds)",
  button_type = "info",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)

```

### **Machine Learning with linear regression**

